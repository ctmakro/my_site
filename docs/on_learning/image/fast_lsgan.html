<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <script>
      (function() {
      var method;
      var methods = [
          'assert', 'clear', 'count', 'debug', 'dir', 'dirxml', 'error',
          'exception', 'group', 'groupCollapsed', 'groupEnd', 'info', 'log',
          'markTimeline', 'profile', 'profileEnd', 'table', 'time', 'timeEnd',
          'timeline', 'timelineEnd', 'timeStamp', 'trace', 'warn'
      ];
      var length = methods.length;
      var console = (window.console = window.console || {});
      while (length--) {
          method = methods[length];
          // Only stub undefined methods.
          if (!console[method]) {
              console[method] = function () {};
          }
      }
      }());
      
      
    </script>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link href="./../../basic.css" rel="stylesheet" type="text/css">
    <link rel="shortcut icon" href="./../../favicon.ico">
    <title>Fast LSGAN in Canton</title>
  </head>
  <body id="body">
    <div class="navigation_area">
      <div class="navnode">
              <div class="navnode_title">/</div>
              <div class="navnode"><a href="./../../index.html">Index</a>
              </div>
              <div class="navnode"><a href="./../../bio.html">About</a>
              </div>
              <div class="navnode">
                      <div class="navnode_title">/art</div>
                      <div class="navnode"><a href="./../../art/anycubic_kossel.html"> Anycubic Kossel 心得</a>
                      </div>
                      <div class="navnode"><a href="./../../art/ferenova.html"> Make a Ferenova</a>
                      </div>
              </div>
              <div class="navnode">
                      <div class="navnode_title">/lit</div>
                      <div class="navnode"><a href="./../../lit/why_bad_idea.html">Why Smart People Have Bad Ideas</a>
                      </div>
              </div>
              <div class="navnode">
                      <div class="navnode_title">/on_learning</div>
                      <div class="navnode"><a href="./../../on_learning/tf1c.html"> Compiling TensorFlow</a>
                      </div>
                      <div class="navnode"><a href="./../../on_learning/course_resources.html">Learning Resources</a>
                      </div>
                      <div class="navnode"><a href="./../../on_learning/fast_gan_in_keras.html"> Fast DCGAN in Keras</a>
                      </div>
                      <div class="navnode"><a href="./../../on_learning/gan.html">GAN 生成式对抗网络</a>
                      </div>
                      <div class="navnode"><a href="./../../on_learning/gd.html">Gradient Descent 梯度下降法</a>
                      </div>
                      <div class="navnode"><a href="./../../on_learning/artist.html">Training of Artists</a>
                      </div>
                      <div class="navnode"><a href="./../../on_learning/how_to.html">Baby steps for ML</a>
                      </div>
                      <div class="navnode"><a href="./../../on_learning/resnet_keras.html">Residual Network in Keras</a>
                      </div>
                      <div class="navnode">
                              <div class="navnode_title">/on_learning/audio</div>
                              <div class="navnode"><a href="./../../on_learning/audio/wavenet_arch.html"> Behind WaveNet</a>
                              </div>
                      </div>
                      <div class="navnode">
                              <div class="navnode_title">/on_learning/image</div>
                              <div class="navnode"><a href="./../../on_learning/image/fast_lsgan.html">Fast LSGAN in Canton</a>
                              </div>
                              <div class="navnode"><a href="./../../on_learning/image/style_transfer.html">On Style Transfer 风格转移</a>
                              </div>
                      </div>
                      <div class="navnode">
                              <div class="navnode_title">/on_learning/motor_model</div>
                              <div class="navnode"><a href="./../../on_learning/motor_model/motor.html">Learn models of motors</a>
                              </div>
                      </div>
                      <div class="navnode">
                              <div class="navnode_title">/on_learning/npeg</div>
                              <div class="navnode"><a href="./../../on_learning/npeg/npeg.html">NPEG图像压缩</a>
                              </div>
                      </div>
                      <div class="navnode">
                              <div class="navnode_title">/on_learning/activations</div>
                              <div class="navnode"><a href="./../../on_learning/activations/index.html">Activation Functions</a>
                              </div>
                              <div class="navnode"><a href="./../../on_learning/activations/relu.html">Rectified Linear Unit 整流线性单元</a>
                              </div>
                      </div>
                      <div class="navnode">
                              <div class="navnode_title">/on_learning/rl</div>
                              <div class="navnode"><a href="./../../on_learning/rl/bipedal.html">BipedalWalker-v2</a>
                              </div>
                              <div class="navnode"><a href="./../../on_learning/rl/ddpg.html">DDPG Method</a>
                              </div>
                              <div class="navnode"><a href="./../../on_learning/rl/l2r.html">Learning to Run</a>
                              </div>
                              <div class="navnode"><a href="./../../on_learning/rl/rl.html">RL is progressing rapidly</a>
                              </div>
                              <div class="navnode"><a href="./../../on_learning/rl/vrep.html">V-REP + Gym = RL</a>
                              </div>
                      </div>
                      <div class="navnode">
                              <div class="navnode_title">/on_learning/gru</div>
                              <div class="navnode"><a href="./../../on_learning/gru/gru.html">GRU and Convolutional GRU</a>
                              </div>
                      </div>
              </div>
              <div class="navnode">
                      <div class="navnode_title">/on_life</div>
                      <div class="navnode"><a href="./../../on_life/beijing.html">北京收获</a>
                      </div>
                      <div class="navnode"><a href="./../../on_life/cc.html">什么是比特币</a>
                      </div>
                      <div class="navnode"><a href="./../../on_life/electrical.html">Power System Analysis</a>
                      </div>
                      <div class="navnode"><a href="./../../on_life/fanqiang.html">一起学翻墙</a>
                      </div>
                      <div class="navnode"><a href="./../../on_life/gd10000.html">广州电信冚家铲</a>
                      </div>
                      <div class="navnode"><a href="./../../on_life/lang.html"> 编程语言的选择</a>
                      </div>
                      <div class="navnode"><a href="./../../on_life/nocode.html"> 不写码 No Code</a>
                      </div>
                      <div class="navnode"><a href="./../../on_life/numjs.html">NumJs</a>
                      </div>
                      <div class="navnode"><a href="./../../on_life/reprod.html"> 确定性</a>
                      </div>
              </div>
      </div>
    </div>
    <div class="markdown_content"><h1 data-sourcepos="3:1-3:35">Fast LSGAN in Canton (TensorFlow)</h1>
<p data-sourcepos="5:1-5:103">LSGAN(<a href="https://arxiv.org/pdf/1611.04076v2.pdf">https://arxiv.org/pdf/1611.04076v2.pdf</a>) is basically DCGAN with MSE loss. (LS for Least Square)</p>
<p data-sourcepos="7:1-7:178">In DCGAN we use sigmoid + cross entropy, so gradients could vanish, which might not be good for learning. In LSGAN the author removed sigmoid and replaced cross entropy with MSE.</p>
<pre><code data-sourcepos="9:1-22:37" class="language-py">generated = g(noise)
gscore = d(generated)
rscore = d(real_data)

# original DCGAN(with single side label smoothing)
dloss = - (log_eps(1-gscore) + .1 * log_eps(1-rscore)+ .9 * log_eps(rscore))
gloss = - log_eps(gscore)

# LSGAN
# note: remove the sigmoid from the discriminator
dloss = tf.reduce_mean((gscore-0)**2 + (rscore-1)**2)
gloss = tf.reduce_mean((gscore-1)**2)
</code></pre>
<p data-sourcepos="24:1-24:97">the code is available at <a href="https://github.com/ctmakro/hellotensor/blob/master/lets_gan_canton.py">https://github.com/ctmakro/hellotensor/blob/master/lets_gan_canton.py</a>.</p>
<p data-sourcepos="26:1-26:122">You should use the same Adam setting as in DCGAN (I use <code>lr=1e-4, beta1=0.5</code>), otherwise the whole thing may not converge.</p>
<p data-sourcepos="28:1-28:7">result:</p>
<p data-sourcepos="30:1-30:29">(after ~40000 x 32 examples):</p>
<p data-sourcepos="32:1-32:23"><img src="lsgan_training.png" alt="" /></p>
<blockquote data-sourcepos="34:1-34:79">
<p data-sourcepos="34:3-34:79">I think the results looked significantly better than those produced by DCGAN.</p>
</blockquote>
<p data-sourcepos="36:1-36:196">after convergence i think it would be boring just producing a minibatch of 32x32 images and post it here, so i increased the size of the input to the generator, generating large 1024x1024 patches:</p>
<p data-sourcepos="38:1-38:27">(after ~20000 x 32 exampes)</p>
<p data-sourcepos="40:1-40:5">LSGAN</p>
<p data-sourcepos="42:1-42:20"><img src="lsgan_large.jpg" alt="" /></p>
<p data-sourcepos="44:1-44:5">DCGAN</p>
<p data-sourcepos="46:1-46:20"><img src="dcgan_large.jpg" alt="" /></p>
<blockquote data-sourcepos="48:1-48:168">
<p data-sourcepos="48:2-48:168">Without the help of image borders, the filters lost their direction to propagate to produce single objects, that's why you can't see meaningful objects in these images</p>
</blockquote>
<p data-sourcepos="50:1-50:85">I'm not sure whether above networks are underfitting or simply require more training.</p>
<p data-sourcepos="52:1-52:51">(placeholder: train overnight and see what happens)</p>
<p data-sourcepos="54:1-54:122">Edit 2017-03-04: so I trained with both least square loss and cross entropy loss, with a learning rate of 1e-5, overnight:</p>
<p data-sourcepos="56:1-56:5">LSGAN</p>
<p data-sourcepos="58:1-58:22"><img src="lsgan_large_2.jpg" alt="" /></p>
<p data-sourcepos="60:1-60:5">DCGAN</p>
<p data-sourcepos="62:1-62:22"><img src="dcgan_large_2.jpg" alt="" /></p>
<p data-sourcepos="64:1-64:132">Apparently with cross entropy loss the DCGAN model is suffering some weird mode of failure, while LSGAN still in it's stable region.</p>
<h2 data-sourcepos="66:1-66:8">Notes</h2>
<ol data-sourcepos="68:1-113:0">
<li data-sourcepos="68:1-91:0">
<p data-sourcepos="68:4-68:380">Please Do Use batch discrimination (within one minibatch, calculate each sample's distance to other samples, then provide that distance as a feature map to next conv layer). The earlier version of my code includes a not-very-good implementation that prevents generator from generating a full batch of identical samples, but won't work if only some of the samples are identical.</p>
<p data-sourcepos="70:5-70:198">according to <a href="https://arxiv.org/abs/1606.03498">https://arxiv.org/abs/1606.03498</a>, their batch discriminator consist of a trainable tensor, by multiplying input batch with that tensor you get a vector of discriminating features.</p>
<p data-sourcepos="72:5-72:88">Instead I simply calculate the L1 diff between tensors, then apply exp(- abs_diff) :</p>
<pre><code data-sourcepos="74:5-88:18" class="language-py">def batch_disc(i):
    #assume i shape [N H W C]
    s = tf.shape(i)
    NHWC1 = tf.expand_dims(i,4)
    AHWCN = tf.expand_dims(tf.transpose(i,[1,2,3,0]),0)
    diffs = NHWC1 - AHWCN # [N H W C N]
    abs_diffs = tf.abs(diffs)
    # shape [N H W C N]
    feat = tf.reduce_mean(tf.exp(-abs_diffs), [3,4])#[N H W]
    feat = tf.expand_dims(feat,3)
    # shape [N H W 1]
    out = tf.concat([i, feat],axis=-1) # [N H W C+1]
    return out
</code></pre>
<p data-sourcepos="90:5-90:118">batch discrimination is very, very important. you can learn more tricks on Ferenc's site <a href="http://www.inference.vc">http://www.inference.vc</a></p>
</li>
<li data-sourcepos="92:1-108:0">
<p data-sourcepos="92:4-92:17">Instance Noise</p>
<p data-sourcepos="94:5-94:107">add noise to both the generator output and the real images, before feeding them into the discriminator.</p>
<pre><code data-sourcepos="96:5-106:32" class="language-py">inl = tf.Variable(1.)

def noisy(i):
    return i + tf.random_normal(mean=0,stddev=inl,shape=tf.shape(i))

generated = g(noise)

gscore = d(noisy(generated))
rscore = d(noisy(real_data))
</code></pre>
<p data-sourcepos="107:5-107:417">then decrease it overtime. This technique blurs the border between the distributions of the generated examples and the real ones, making it harder for the discriminator, and easier for the generator. due to the noise, the discriminator cannot use details to discriminate between real and fake examples, therefore it wont force the generator to generate details (that could lead to mode collapse) in the beginning.</p>
</li>
<li data-sourcepos="109:1-113:0">
<p data-sourcepos="109:4-109:18">too much tricks</p>
<p data-sourcepos="111:5-111:114">to get results like those in goodfellow's paper, you have to try all his tricks. I don't have time for that...</p>
</li>
</ol>
<h2 data-sourcepos="114:1-114:40">Notes on deconv (or conv2d_transpose)</h2>
<p data-sourcepos="116:1-116:37">DCGAN uses deconv to upsample images.</p>
<ol data-sourcepos="118:1-120:0">
<li data-sourcepos="118:1-118:56">inconvenient (you have to set output shapes manually)</li>
<li data-sourcepos="119:1-120:0">produce tiling artifacts</li>
</ol>
<p data-sourcepos="121:1-121:102">instead we use nearest neighbour upsampling, offered in <code>canton</code> as <code>ct.Up2D()</code>, followed by a conv2d.</p>
<p data-sourcepos="123:1-123:36">here's our Generator implementation:</p>
<pre><code data-sourcepos="125:1-147:12" class="language-py">def gen_gen():
    c = Can()
    def deconv(nip,nop,tail=True,upscale=2):
        dc = Can()
        dc.add(Up2D(upscale))
        dc.add(Conv2D(nip,nop,k=4,std=1,usebias=not tail))
        if tail:
            dc.add(BatchNorm(nop))
            dc.add(Act('relu'))
        dc.chain()
        return dc

    ngf = 32
    c.add(deconv(zed,ngf*8,upscale=4)) #4
    c.add(deconv(ngf*8,ngf*4))
    c.add(deconv(ngf*4,ngf*2))
    c.add(deconv(ngf*2,ngf*1)) #32
    c.add(deconv(ngf*1,3,tail=False,upscale=1))
    c.add(Act('tanh'))
    c.chain()
    return c
</code></pre>
<p data-sourcepos="149:1-149:234">The generated quality is better than using deconv. No checkboard, yet banding still. For best upsampling behavior, you should consider ESPCN (<a href="http://www.inference.vc/holiday-special-deriving-the-subpixel-cnn-from-first-principles/">http://www.inference.vc/holiday-special-deriving-the-subpixel-cnn-from-first-principles/</a>).</p>
<h2 data-sourcepos="151:1-151:17">What is Canton</h2>
<p data-sourcepos="153:1-153:175">A lightweight wrapper around TensorFlow. It offers convenience of Keras but never get into your way. It's also much faster at construction because it doesn't check the shapes.</p>
<p data-sourcepos="155:1-155:54">you may fork canton on GitHub or <code>pip install canton</code>.</p>
</div>
    <div class="meta_string">
      <p>file: fast_lsgan.md</p>
      <p>last modified: 2017-03-04 20:17</p>
    </div>
    <script>
      //if(window.HighlightEverything){window.HighlightEverything()}
      
    </script>
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/styles/atom-one-light.min.css">
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/highlight.min.js"></script>
    <script>
      hljs.initHighlightingOnLoad();
      
    </script>
    <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet">
  </body>
</html>