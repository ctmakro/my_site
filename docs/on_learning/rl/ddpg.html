<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <script>
      (function() {
      var method;
      var methods = [
          'assert', 'clear', 'count', 'debug', 'dir', 'dirxml', 'error',
          'exception', 'group', 'groupCollapsed', 'groupEnd', 'info', 'log',
          'markTimeline', 'profile', 'profileEnd', 'table', 'time', 'timeEnd',
          'timeline', 'timelineEnd', 'timeStamp', 'trace', 'warn'
      ];
      var length = methods.length;
      var console = (window.console = window.console || {});
      while (length--) {
          method = methods[length];
          // Only stub undefined methods.
          if (!console[method]) {
              console[method] = function () {};
          }
      }
      }());
      
      
    </script>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link href="./../../basic.css" rel="stylesheet" type="text/css">
    <link rel="shortcut icon" href="./../../favicon.ico">
    <title>DDPG Method</title>
  </head>
  <body id="body">
    <div class="navigation_area">
      <div class="navnode">
              <div class="navnode_title">/</div>
              <div class="navnode"><a href="./../../index.html">Index</a>
              </div>
              <div class="navnode"><a href="./../../bio.html">About</a>
              </div>
              <div class="navnode">
                      <div class="navnode_title">/art</div>
                      <div class="navnode"><a href="./../../art/anycubic_kossel.html"> Anycubic Kossel 心得</a>
                      </div>
                      <div class="navnode"><a href="./../../art/ferenova.html"> Make a Ferenova</a>
                      </div>
              </div>
              <div class="navnode">
                      <div class="navnode_title">/lit</div>
                      <div class="navnode"><a href="./../../lit/why_bad_idea.html">Why Smart People Have Bad Ideas</a>
                      </div>
              </div>
              <div class="navnode">
                      <div class="navnode_title">/on_learning</div>
                      <div class="navnode"><a href="./../../on_learning/tf1c.html"> Compiling TensorFlow</a>
                      </div>
                      <div class="navnode"><a href="./../../on_learning/course_resources.html">Learning Resources</a>
                      </div>
                      <div class="navnode"><a href="./../../on_learning/fast_gan_in_keras.html"> Fast DCGAN in Keras</a>
                      </div>
                      <div class="navnode"><a href="./../../on_learning/gan.html">GAN 生成式对抗网络</a>
                      </div>
                      <div class="navnode"><a href="./../../on_learning/gd.html">Gradient Descent 梯度下降法</a>
                      </div>
                      <div class="navnode"><a href="./../../on_learning/artist.html">Training of Artists</a>
                      </div>
                      <div class="navnode"><a href="./../../on_learning/how_to.html">Baby steps for ML</a>
                      </div>
                      <div class="navnode"><a href="./../../on_learning/resnet_keras.html">Residual Network in Keras</a>
                      </div>
                      <div class="navnode">
                              <div class="navnode_title">/on_learning/audio</div>
                              <div class="navnode"><a href="./../../on_learning/audio/wavenet_arch.html"> Behind WaveNet</a>
                              </div>
                      </div>
                      <div class="navnode">
                              <div class="navnode_title">/on_learning/image</div>
                              <div class="navnode"><a href="./../../on_learning/image/fast_lsgan.html">Fast LSGAN in Canton</a>
                              </div>
                              <div class="navnode"><a href="./../../on_learning/image/style_transfer.html">On Style Transfer 风格转移</a>
                              </div>
                      </div>
                      <div class="navnode">
                              <div class="navnode_title">/on_learning/motor_model</div>
                              <div class="navnode"><a href="./../../on_learning/motor_model/motor.html">Learn models of motors</a>
                              </div>
                      </div>
                      <div class="navnode">
                              <div class="navnode_title">/on_learning/npeg</div>
                              <div class="navnode"><a href="./../../on_learning/npeg/npeg.html">NPEG图像压缩</a>
                              </div>
                      </div>
                      <div class="navnode">
                              <div class="navnode_title">/on_learning/activations</div>
                              <div class="navnode"><a href="./../../on_learning/activations/index.html">Activation Functions</a>
                              </div>
                              <div class="navnode"><a href="./../../on_learning/activations/relu.html">Rectified Linear Unit 整流线性单元</a>
                              </div>
                      </div>
                      <div class="navnode">
                              <div class="navnode_title">/on_learning/rl</div>
                              <div class="navnode"><a href="./../../on_learning/rl/bipedal.html">BipedalWalker-v2</a>
                              </div>
                              <div class="navnode"><a href="./../../on_learning/rl/ddpg.html">DDPG Method</a>
                              </div>
                              <div class="navnode"><a href="./../../on_learning/rl/l2r.html">Learning to Run</a>
                              </div>
                              <div class="navnode"><a href="./../../on_learning/rl/musicgen.html">Music Generation</a>
                              </div>
                              <div class="navnode"><a href="./../../on_learning/rl/rl.html">RL is progressing rapidly</a>
                              </div>
                              <div class="navnode"><a href="./../../on_learning/rl/vrep.html">V-REP + Gym = RL</a>
                              </div>
                      </div>
                      <div class="navnode">
                              <div class="navnode_title">/on_learning/gru</div>
                              <div class="navnode"><a href="./../../on_learning/gru/gru.html">GRU and Convolutional GRU</a>
                              </div>
                      </div>
              </div>
              <div class="navnode">
                      <div class="navnode_title">/on_life</div>
                      <div class="navnode"><a href="./../../on_life/beijing.html">北京收获</a>
                      </div>
                      <div class="navnode"><a href="./../../on_life/cc.html">什么是比特币</a>
                      </div>
                      <div class="navnode"><a href="./../../on_life/electrical.html">Power System Analysis</a>
                      </div>
                      <div class="navnode"><a href="./../../on_life/fanqiang.html">一起学翻墙</a>
                      </div>
                      <div class="navnode"><a href="./../../on_life/gd10000.html">广州电信冚家铲</a>
                      </div>
                      <div class="navnode"><a href="./../../on_life/lang.html"> 编程语言的选择</a>
                      </div>
                      <div class="navnode"><a href="./../../on_life/nocode.html"> 不写码 No Code</a>
                      </div>
                      <div class="navnode"><a href="./../../on_life/numjs.html">NumJs</a>
                      </div>
                      <div class="navnode"><a href="./../../on_life/reprod.html"> 确定性</a>
                      </div>
              </div>
      </div>
    </div>
    <div class="markdown_content"><h1 data-sourcepos="3:1-3:43">Deep Deterministic Policy Gradient Method</h1>
<p data-sourcepos="5:1-5:52">Paper's here: <a href="https://arxiv.org/pdf/1509.02971.pdf">https://arxiv.org/pdf/1509.02971.pdf</a></p>
<p data-sourcepos="7:1-7:73">Basically you have two network, one called the <code>actor</code>, another <code>critic</code>.</p>
<ul data-sourcepos="9:1-11:0">
<li data-sourcepos="9:1-9:51">The actor take state as input and outputs actions</li>
<li data-sourcepos="10:1-11:0">The critic take state-action pairs as input and outputs the Q value</li>
</ul>
<p data-sourcepos="12:1-12:308">In DDPG the actor perform a deterministic policy (given input, the output is not a probabilistic distribution, but a value). We let the critic to judge how good did the actor do; then the actor can use this information to improve its policy. The problem then become: how can we train such a network in Keras?</p>
<blockquote data-sourcepos="14:1-14:146">
<p data-sourcepos="14:3-14:146">Of course you can't. For my own convenience I wrote a small library called <code>canton</code>. Check <a href="https://github.com/ctmakro/canton">https://github.com/ctmakro/canton</a> for more details.</p>
</blockquote>
<ol data-sourcepos="16:1-77:0">
<li data-sourcepos="16:1-25:0">
<p data-sourcepos="16:4-16:64">Define the inputs: (state, action, reward, done?, next-state)</p>
<pre><code data-sourcepos="18:5-24:63" class="language-py">s1 = tf.placeholder(tf.float32,shape=[None,self.inputdims])
a1 = tf.placeholder(tf.float32,shape=[None,self.outputdims])
r1 = tf.placeholder(tf.float32,shape=[None,1])
isdone = tf.placeholder(tf.float32,shape=[None,1])
s2 = tf.placeholder(tf.float32,shape=[None,self.inputdims])
</code></pre>
</li>
<li data-sourcepos="26:1-35:0">
<p data-sourcepos="26:4-26:112">Train the critic by minimizing the MSE loss between predicted Q and calculated Q (using Temporal-Difference):</p>
<pre><code data-sourcepos="28:5-34:61" class="language-py">a2 = self.actor_target(s2)
q2 = self.critic_target([s2,a2])
q1_target = r1 + (1-isdone) * self.discount_factor * q2
q1_predict = self.critic([s1,a1])
critic_loss = tf.reduce_mean((q1_target - q1_predict)**2)
</code></pre>
</li>
<li data-sourcepos="36:1-43:0">
<p data-sourcepos="36:4-36:53">Train the actor by maximizing the expected reward:</p>
<pre><code data-sourcepos="38:5-42:45" class="language-py">a1_predict = self.actor(s1)
q1_predict = self.critic([s1,a1_predict])
actor_loss = tf.reduce_mean(- q1_predict)
</code></pre>
</li>
<li data-sourcepos="44:1-58:0">
<p data-sourcepos="44:4-44:258">You may have noticed that there are two network called &quot;actor_target&quot; and &quot;critic_target&quot;. They are copies of actor and critc, with their weights slowly gradually updated from actor and critic (to reduce action-sample correlation thus stabilize learning).</p>
<pre><code data-sourcepos="46:5-57:33" class="language-py">tau = tf.Variable(0.001)
aw = self.actor.get_weights()
atw = self.actor_target.get_weights()
cw = self.critic.get_weights()
ctw = self.critic_target.get_weights()

shift1 = [tf.assign(atw[i], aw[i]*tau + atw[i]*(1-tau))
    for i,_ in enumerate(aw)]
shift2 = [tf.assign(ctw[i], cw[i]*tau + ctw[i]*(1-tau))
    for i,_ in enumerate(cw)]
</code></pre>
</li>
<li data-sourcepos="59:1-77:0">
<p data-sourcepos="59:4-59:207">That's it. By using the <code>canton</code> library, instead of creating multiple versions of networks in Keras or dealing with variable scopes in TensorFlow, you can now update everything in one <code>tf.Session.run()</code>:</p>
<pre><code data-sourcepos="61:5-76:14" class="language-py">opt = tf.train.RMSPropOptimizer(1e-4)
    cstep = opt.minimize(critic_loss,
        var_list=self.critic.get_weights())
    astep = opt.minimize(actor_loss,
        var_list=self.actor.get_weights())

def feed(memory):
    [s1d,a1d,r1d,isdoned,s2d] = memory # d suffix means data
    sess = ct.get_session()
    res = sess.run([critic_loss,actor_loss,
        cstep,astep,shift1,shift2],
        feed_dict={
        s1:s1d,a1:a1d,r1:r1d,isdone:isdoned,s2:s2d,tau:1e-3
        })
</code></pre>
</li>
</ol>
<p data-sourcepos="78:1-78:78">Code available at <a href="https://github.com/ctmakro/gymnastics/blob/master/ddpg.py">https://github.com/ctmakro/gymnastics/blob/master/ddpg.py</a>.</p>
<p data-sourcepos="80:1-80:28">At the time of this writing:</p>
<ul data-sourcepos="82:1-91:203">
<li data-sourcepos="82:1-82:87">
<p data-sourcepos="82:3-82:87">I added some 1/f noise to the output at the beginning of learning, change if you want</p>
</li>
<li data-sourcepos="83:1-86:0">
<p data-sourcepos="83:3-83:148">There's an oscilloscope-like window (hand-drawn in <code>numpy</code>, display with <code>cv2</code>) showing the current action value and Q-value, remove if not needed</p>
<p data-sourcepos="85:5-85:25"><img src="ddpg_running.png" alt="" /></p>
</li>
<li data-sourcepos="87:1-91:203">
<p data-sourcepos="87:3-87:205">I won the 2nd and 3rd place on <code>Pendulum-V0</code> (the 2nd and 3rd place submission are actually based on an older implementation of DDPG using Keras, which is extremely verbose thus not recommended reading).</p>
<p data-sourcepos="89:5-89:18"><img src="queen.png" alt="" /></p>
<p data-sourcepos="91:5-91:203">(Gym put recent submissions on top. My final performance is actually worse than John Schulman's TRPO implementation, due to instability of RMSProp IMO. But my agent also learn much faster than his :)</p>
</li>
</ul>
</div>
    <div class="meta_string">
      <p>file: ddpg.md</p>
      <p>last modified: 2017-02-18 22:08</p>
    </div>
    <script>
      //if(window.HighlightEverything){window.HighlightEverything()}
      
    </script>
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/styles/atom-one-light.min.css">
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/highlight.min.js"></script>
    <script>
      hljs.initHighlightingOnLoad();
      
    </script>
    <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet">
  </body>
</html>